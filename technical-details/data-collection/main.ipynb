{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Collection\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{{< include overview.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include methods.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n",
    "Provide the source code used for this section of the project here.\n",
    "\n",
    "If you're using a package for code organization, you can import it at this point. However, make sure that the **actual workflow steps**—including data processing, analysis, and other key tasks—are conducted and clearly demonstrated on this page. The goal is to show the technical flow of your project, highlighting how the code is executed to achieve your results.\n",
    "\n",
    "Ensure that the code is well-commented to enhance readability and understanding for others who may review or use it. If relevant, link to additional documentation or external references that explain any complex components. This section should give readers a clear view of how the project is implemented from a technical perspective.\n",
    "\n",
    "This page is a technical narrative, NOT just a notebook with a collection of code cells, include in-line Prose, to describe what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by examining the dataset gained from the  American Trends Panel Wave 111 conducted by the Pew Research Center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    QKEY INTERVIEW_START_W111  INTERVIEW_END_W111 DEVICE_TYPE_W111 LANG_W111  \\\n",
      "0  113.0  2022-07-05 16:28:49 2022-07-06 03:44:16       Smartphone   English   \n",
      "1  115.0  2022-07-05 16:28:59 2022-07-16 20:39:46       Smartphone   English   \n",
      "2  116.0  2022-07-05 16:29:59 2022-07-05 16:39:21           Tablet   English   \n",
      "3  117.0  2022-07-05 16:30:18 2022-07-05 16:36:32        Laptop/PC   English   \n",
      "4  119.0  2022-07-05 16:30:35 2022-07-05 16:38:35       Smartphone   English   \n",
      "\n",
      "    XTABLET_W111        SHOP18_W111  \\\n",
      "0  Non-tablet HH               Some   \n",
      "1  Non-tablet HH               None   \n",
      "2  Non-tablet HH  All or almost all   \n",
      "3  Non-tablet HH               Some   \n",
      "4  Non-tablet HH               None   \n",
      "\n",
      "                                         SHOP19_W111  \\\n",
      "0  I try to make sure that I always have cash wit...   \n",
      "1  I don’t really worry much about whether or not...   \n",
      "2  I don’t really worry much about whether or not...   \n",
      "3  I don’t really worry much about whether or not...   \n",
      "4  I don’t really worry much about whether or not...   \n",
      "\n",
      "                  METOO1_W111  \\\n",
      "0            Strongly support   \n",
      "1            Strongly support   \n",
      "2  Neither support nor oppose   \n",
      "3            Somewhat support   \n",
      "4            Strongly support   \n",
      "\n",
      "                                  METOOSUPOE_M1_W111  ... F_PARTYLN_FINAL  \\\n",
      "0          Women need or deserve equality or respect  ...             NaN   \n",
      "1                                                NaN  ...             NaN   \n",
      "2                                                NaN  ...             NaN   \n",
      "3          Women need or deserve equality or respect  ...             NaN   \n",
      "4  Personal experiences (of the respondent or som...  ...             NaN   \n",
      "\n",
      "  F_PARTYSUM_FINAL F_PARTYSUMIDEO_FINAL                     F_INC_SDT1  \\\n",
      "0     Dem/Lean Dem     Liberal Dem/Lean  $90,000 to less than $100,000   \n",
      "1     Dem/Lean Dem     Liberal Dem/Lean  $90,000 to less than $100,000   \n",
      "2     Dem/Lean Dem     Liberal Dem/Lean               $100,000 or more   \n",
      "3     Dem/Lean Dem     Liberal Dem/Lean              Less than $30,000   \n",
      "4     Dem/Lean Dem     Liberal Dem/Lean   $50,000 to less than $60,000   \n",
      "\n",
      "                                               F_REG        F_IDEO  \\\n",
      "0  You are PROBABLY registered, but there is a ch...       Liberal   \n",
      "1  You are ABSOLUTELY CERTAIN that you are regist...  Very liberal   \n",
      "2  You are ABSOLUTELY CERTAIN that you are regist...       Liberal   \n",
      "3  You are ABSOLUTELY CERTAIN that you are regist...       Liberal   \n",
      "4  You are ABSOLUTELY CERTAIN that you are regist...  Very liberal   \n",
      "\n",
      "             F_INTFREQ F_VOLSUM    F_INC_TIER2 WEIGHT_W111  \n",
      "0  Several times a day      Yes  Middle income    0.582137  \n",
      "1    Almost constantly       No  Middle income    0.094086  \n",
      "2    Almost constantly       No   Upper income    0.072813  \n",
      "3    Almost constantly       No   Lower income    0.713802  \n",
      "4    Almost constantly      Yes  Middle income    0.091391  \n",
      "\n",
      "[5 rows x 139 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read in raw data - a sav file\n",
    "W111_df = pd.read_spss(\"../../data/raw-data/ATP_W111.sav\")\n",
    "\n",
    "#View the first several rows of the data\n",
    "print(W111_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the Data Frame has a 6034 rows and 139 columns. That implies there will need to be some columns to be eliminated which will be done in the data cleaning step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6034, 139)\n",
      "Index(['QKEY', 'INTERVIEW_START_W111', 'INTERVIEW_END_W111',\n",
      "       'DEVICE_TYPE_W111', 'LANG_W111', 'XTABLET_W111', 'SHOP18_W111',\n",
      "       'SHOP19_W111', 'METOO1_W111', 'METOOSUPOE_M1_W111',\n",
      "       ...\n",
      "       'F_PARTYLN_FINAL', 'F_PARTYSUM_FINAL', 'F_PARTYSUMIDEO_FINAL',\n",
      "       'F_INC_SDT1', 'F_REG', 'F_IDEO', 'F_INTFREQ', 'F_VOLSUM', 'F_INC_TIER2',\n",
      "       'WEIGHT_W111'],\n",
      "      dtype='object', length=139)\n"
     ]
    }
   ],
   "source": [
    "# Disply data frame shape and column titles\n",
    "print(W111_df.shape)\n",
    "print(W111_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find that 4 out of the 139 columns are non-categorical which implies, we have to continue searching for data for a regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QKEY                           float64\n",
      "INTERVIEW_START_W111    datetime64[ns]\n",
      "INTERVIEW_END_W111      datetime64[ns]\n",
      "DEVICE_TYPE_W111              category\n",
      "LANG_W111                     category\n",
      "                             ...      \n",
      "F_IDEO                        category\n",
      "F_INTFREQ                     category\n",
      "F_VOLSUM                      category\n",
      "F_INC_TIER2                   category\n",
      "WEIGHT_W111                    float64\n",
      "Length: 139, dtype: object\n",
      "['QKEY', 'INTERVIEW_START_W111', 'INTERVIEW_END_W111', 'WEIGHT_W111']\n"
     ]
    }
   ],
   "source": [
    "# Display column data types\n",
    "print(W111_df.dtypes)\n",
    "non_categorical_columns = []\n",
    "for col in W111_df.columns:\n",
    "    if W111_df[col].dtype != \"category\":\n",
    "        non_categorical_columns.append(col)\n",
    "        \n",
    "print(non_categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import and view the 2023 Consumer Expenditure Survey Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import data for income\n",
    "income_1_df = pd.read_csv(\"../../data/raw-data/itii232.csv\")\n",
    "income_2_df = pd.read_csv(\"../../data/raw-data/itii233.csv\")\n",
    "income_3_df = pd.read_csv(\"../../data/raw-data/itii234.csv\")\n",
    "income_4_df = pd.read_csv(\"../../data/raw-data/itii241.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the the Data Frames have 8 columns. Their shapes are displayed below. We find that the data frames have identical columns so they can be merged in the data collection stage, and we can filter for relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           NEWID  REFMO  REFYR     UCC  PUBFLAG VALUE_  IMPNUM        VALUE\n",
      "0       5090604      1   2023  900030        2    NaN       1  3169.833300\n",
      "1       5090604      1   2023  900030        2    NaN       2  3169.833300\n",
      "2       5090604      1   2023  900030        2    NaN       3  3169.833300\n",
      "3       5090604      1   2023  900030        2    NaN       4  3169.833300\n",
      "4       5090604      1   2023  900030        2    NaN       5  3169.833300\n",
      "...         ...    ...    ...     ...      ...    ...     ...          ...\n",
      "330445  5366911      5   2023  980071        2    NaN       1   820.250000\n",
      "330446  5366911      5   2023  980071        2    NaN       2   250.000000\n",
      "330447  5366911      5   2023  980071        2    NaN       3   100.000000\n",
      "330448  5366911      5   2023  980071        2    NaN       4   294.666667\n",
      "330449  5366911      5   2023  980071        2    NaN       5   160.250000\n",
      "\n",
      "[330450 rows x 8 columns]>\n",
      "<bound method NDFrame.head of           NEWID  REFMO  REFYR     UCC  PUBFLAG VALUE_  IMPNUM         VALUE\n",
      "0       5201374      4   2023  800940        2    NaN       1    156.333300\n",
      "1       5201374      4   2023  800940        2    NaN       2    190.833300\n",
      "2       5201374      4   2023  800940        2    NaN       3    186.583300\n",
      "3       5201374      4   2023  800940        2    NaN       4    142.000000\n",
      "4       5201374      4   2023  800940        2    NaN       5    178.416700\n",
      "...         ...    ...    ...     ...      ...    ...     ...           ...\n",
      "330835  5446571      8   2023  980071        2    NaN       1  12866.833333\n",
      "330836  5446571      8   2023  980071        2    NaN       2  12866.833333\n",
      "330837  5446571      8   2023  980071        2    NaN       3  12866.833333\n",
      "330838  5446571      8   2023  980071        2    NaN       4  12866.833333\n",
      "330839  5446571      8   2023  980071        2    NaN       5  12866.833333\n",
      "\n",
      "[330840 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(income_1_df.head)\n",
    "print(income_2_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           NEWID  REFMO  REFYR     UCC  PUBFLAG VALUE_  IMPNUM   VALUE\n",
      "0       5251754      7   2023  800940        2    NaN       1   382.5\n",
      "1       5251754      7   2023  800940        2    NaN       2   382.5\n",
      "2       5251754      7   2023  800940        2    NaN       3   382.5\n",
      "3       5251754      7   2023  800940        2    NaN       4   382.5\n",
      "4       5251754      7   2023  800940        2    NaN       5   382.5\n",
      "...         ...    ...    ...     ...      ...    ...     ...     ...\n",
      "322315  5573581     11   2023  980071        2    NaN       1  6802.0\n",
      "322316  5573581     11   2023  980071        2    NaN       2  6802.0\n",
      "322317  5573581     11   2023  980071        2    NaN       3  6802.0\n",
      "322318  5573581     11   2023  980071        2    NaN       4  6802.0\n",
      "322319  5573581     11   2023  980071        2    NaN       5  6802.0\n",
      "\n",
      "[322320 rows x 8 columns]>\n",
      "<bound method NDFrame.head of           NEWID  REFMO  REFYR     UCC  PUBFLAG VALUE_  IMPNUM        VALUE\n",
      "0       5286244     10   2023  900090        2    NaN       1   133.333300\n",
      "1       5286244     10   2023  900090        2    NaN       2   133.333300\n",
      "2       5286244     10   2023  900090        2    NaN       3   133.333300\n",
      "3       5286244     10   2023  900090        2    NaN       4   133.333300\n",
      "4       5286244     10   2023  900090        2    NaN       5   133.333300\n",
      "...         ...    ...    ...     ...      ...    ...     ...          ...\n",
      "325195  5608061     12   2023  980071        2    NaN       1  2161.333333\n",
      "325196  5608061     12   2023  980071        2    NaN       2  2161.333333\n",
      "325197  5608061     12   2023  980071        2    NaN       3  2161.333333\n",
      "325198  5608061     12   2023  980071        2    NaN       4  2161.333333\n",
      "325199  5608061     12   2023  980071        2    NaN       5  2161.333333\n",
      "\n",
      "[325200 rows x 8 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(income_3_df.head)\n",
    "print(income_4_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more datasets: mtbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "In the following code, we first utilized the requests library to retrieve the HTML content from the Wikipedia page. Afterward, we employed BeautifulSoup to parse the HTML and locate the specific table of interest by using the find function. Once the table was identified, we extracted the relevant data by iterating through its rows, gathering country names and their respective populations. Finally, we used Pandas to store the collected data in a DataFrame, allowing for easy analysis and visualization. The data could also be optionally saved as a CSV file for further use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Country     Population\n",
      "0                                  World  8,119,000,000\n",
      "1                                  China  1,409,670,000\n",
      "2                          1,404,910,000          17.3%\n",
      "3                          United States    335,893,238\n",
      "4                              Indonesia    281,603,800\n",
      "..                                   ...            ...\n",
      "235                   Niue (New Zealand)          1,681\n",
      "236                Tokelau (New Zealand)          1,647\n",
      "237                         Vatican City            764\n",
      "238  Cocos (Keeling) Islands (Australia)            593\n",
      "239                Pitcairn Islands (UK)             35\n",
      "\n",
      "[240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Send a request to Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the table containing the data (usually the first table for such lists)\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract data from the table rows\n",
    "countries = []\n",
    "populations = []\n",
    "\n",
    "# Iterate over the table rows\n",
    "for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) > 1:\n",
    "        country = cells[1].text.strip()  # The country name is in the second column\n",
    "        population = cells[2].text.strip()  # The population is in the third column\n",
    "        countries.append(country)\n",
    "        populations.append(population)\n",
    "\n",
    "# Step 5: Create a DataFrame to store the results\n",
    "data = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Population': populations\n",
    "})\n",
    "\n",
    "# Display the scraped data\n",
    "print(data)\n",
    "\n",
    "# Optionally save to CSV\n",
    "data.to_csv('../../data/raw-data/countries_population.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include closing.qmd >}} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
